File Name: company_researcher.py

-----------------------------

File Content: 

import asyncio
import json
import os
from typing import Dict, Any
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from tavily import TavilyClient

from models import ResearchState, CompanyInfo
from nodes import QueryGenerationNode, WebSearchNode, InformationExtractionNode, ReflectionNode


class CompanyResearcher:
    """Main company researcher using LangGraph"""
    
    def __init__(
        self, 
        openai_api_key: str = None,
        tavily_api_key: str = None,
        model: str = "gpt-4",
        max_search_queries: int = 8,
        max_search_results: int = 50,
        max_reflections: int = 3
    ):
        # Load environment variables
        load_dotenv()
        
        # Initialize LLM
        self.llm = ChatOpenAI(
            api_key=openai_api_key or os.getenv("OPENAI_API_KEY"),
            model=model,
            temperature=0.1
        )
        
        # Initialize Tavily client
        self.tavily_client = TavilyClient(
            api_key=tavily_api_key or os.getenv("TAVILY_API_KEY")
        )
        
        # Configuration
        self.max_search_queries = max_search_queries
        self.max_search_results = max_search_results
        self.max_reflections = max_reflections
        
        # Initialize nodes
        self.query_node = QueryGenerationNode(self.llm)
        self.search_node = WebSearchNode(self.tavily_client)
        self.extraction_node = InformationExtractionNode(self.llm)
        self.reflection_node = ReflectionNode(self.llm)
        
        # Build the graph
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """Build the LangGraph workflow"""
        
        # Create the state graph
        workflow = StateGraph(ResearchState)
        
        # Add nodes
        workflow.add_node("generate_queries", self.query_node)
        workflow.add_node("web_search", self.search_node) 
        workflow.add_node("extract_info", self.extraction_node)
        workflow.add_node("reflect", self.reflection_node)
        
        # Define the workflow edges
        workflow.set_entry_point("generate_queries")
        
        # Generate queries -> Web search
        workflow.add_edge("generate_queries", "web_search")
        
        # Web search -> Extract information
        workflow.add_edge("web_search", "extract_info")
        
        # Extract information -> Reflect
        workflow.add_edge("extract_info", "reflect")
        
        # Conditional edge from reflect
        def should_continue(state: ResearchState) -> str:
            """Determine if research should continue"""
            if state.research_complete:
                return END
            else:
                return "generate_queries"  # Generate more queries
        
        workflow.add_conditional_edges(
            "reflect",
            should_continue
        )
        
        return workflow.compile()
    
    async def research_company(
        self, 
        company_name: str, 
        user_notes: str = None
    ) -> Dict[str, Any]:
        """Research a company and return structured information"""
        
        # Initialize state
        initial_state = ResearchState(
            company_name=company_name,
            user_notes=user_notes,
            company_info=CompanyInfo(company_name=company_name),
            max_search_queries=self.max_search_queries,
            max_search_results=self.max_search_results,
            max_reflections=self.max_reflections
        )
        
        print(f"🔍 Starting research for: {company_name}")
        if user_notes:
            print(f"📝 User notes: {user_notes}")
        
        # Run the graph
        final_state = await self.graph.ainvoke(initial_state)
        
        # Prepare results
        results = {
            "company_info": final_state.company_info.model_dump(),
            "research_summary": {
                "queries_executed": final_state.queries_executed,
                "max_queries": final_state.max_search_queries,
                "results_collected": len(final_state.search_results),
                "reflections_done": final_state.reflections_done,
                "research_complete": final_state.research_complete
            },
            "messages": final_state.messages,
            "search_queries": [q.model_dump() for q in final_state.search_queries_generated]
        }
        
        return results
    
    def print_results(self, results: Dict[str, Any]) -> None:
        """Print formatted research results"""
        
        company_info = results["company_info"]
        summary = results["research_summary"]
        
        print("\n" + "="*50)
        print(f"📊 COMPANY RESEARCH RESULTS")
        print("="*50)
        
        print(f"\n🏢 Company: {company_info['company_name']}")
        
        if company_info.get('founding_year'):
            print(f"📅 Founded: {company_info['founding_year']}")
        
        if company_info.get('founder_names'):
            founders = ", ".join(company_info['founder_names'])
            print(f"👥 Founders: {founders}")
        
        if company_info.get('product_description'):
            print(f"🚀 Product: {company_info['product_description']}")
        
        if company_info.get('funding_summary'):
            print(f"💰 Funding: {company_info['funding_summary']}")
        
        if company_info.get('notable_customers'):
            print(f"🤝 Customers: {company_info['notable_customers']}")
        
        print(f"\n📈 Research Summary:")
        print(f"   • Search queries: {summary['queries_executed']}/{summary['max_queries']}")
        print(f"   • Results collected: {summary['results_collected']}")
        print(f"   • Reflections: {summary['reflections_done']}")
        print(f"   • Complete: {'✅' if summary['research_complete'] else '❌'}")
        
        print("\n" + "="*50)


# Convenience function for quick research
async def research_company(
    company_name: str,
    user_notes: str = None,
    **kwargs
) -> Dict[str, Any]:
    """Quick research function"""
    researcher = CompanyResearcher(**kwargs)
    return await researcher.research_company(company_name, user_notes)


if __name__ == "__main__":
    # Example usage
    async def main():
        # Example research
        results = await research_company(
            company_name="OpenAI",
            user_notes="Focus on recent developments and partnerships"
        )
        
        # Print results
        researcher = CompanyResearcher()
        researcher.print_results(results)
        
        # Save to file
        with open("research_results.json", "w") as f:
            json.dump(results, f, indent=2)
        
        print(f"\n💾 Results saved to: research_results.json")
    
    # Run the example
    asyncio.run(main())



File Name: config.py

-----------------------------

File Content: 

"""Configuration settings for the Company Researcher"""

from typing import Dict, Any
from dataclasses import dataclass


@dataclass
class ResearchConfig:
    """Configuration for research parameters"""
    
    # API Configuration
    openai_model: str = "gpt-4"
    openai_temperature: float = 0.1
    
    # Search Limits
    max_search_queries: int = 8
    max_search_results: int = 50
    max_reflections: int = 3
    
    # Concurrent Search Settings
    max_concurrent_searches: int = 3
    
    # Search Settings
    tavily_search_depth: str = "basic"  # "basic" or "advanced"
    tavily_max_results_per_query: int = 5
    
    # Content Processing
    max_content_length: int = 500  # Characters per search result
    recent_results_window: int = 10  # Number of recent results to process
    
    # Validation
    min_required_fields: int = 2  # Minimum fields required to consider research complete
    

class DefaultConfigs:
    """Pre-configured settings for different use cases"""
    
    @staticmethod
    def quick_research() -> ResearchConfig:
        """Fast research with minimal queries"""
        return ResearchConfig(
            max_search_queries=4,
            max_search_results=20,
            max_reflections=1,
            tavily_max_results_per_query=3
        )
    
    @staticmethod
    def thorough_research() -> ResearchConfig:
        """Comprehensive research with more queries"""
        return ResearchConfig(
            max_search_queries=12,
            max_search_results=80,
            max_reflections=5,
            tavily_search_depth="advanced",
            tavily_max_results_per_query=7
        )
    
    @staticmethod
    def balanced_research() -> ResearchConfig:
        """Default balanced approach"""
        return ResearchConfig()


# Environment variable requirements
REQUIRED_ENV_VARS = [
    "OPENAI_API_KEY",
    "TAVILY_API_KEY"
]


def validate_environment() -> Dict[str, Any]:
    """Validate that required environment variables are set"""
    import os
    
    missing_vars = []
    for var in REQUIRED_ENV_VARS:
        if not os.getenv(var):
            missing_vars.append(var)
    
    return {
        "valid": len(missing_vars) == 0,
        "missing_variables": missing_vars,
        "message": f"Missing environment variables: {missing_vars}" if missing_vars else "All required environment variables are set"
    }



File Name: example_usage.py

-----------------------------

File Content: 

#!/usr/bin/env python3
"""
Example usage of the Company Researcher

This script demonstrates different ways to use the company researcher:
1. Basic research
2. Research with user notes
3. Custom configuration
4. Batch research for multiple companies
"""

import asyncio
import json
from typing import List, Dict, Any

from company_researcher import CompanyResearcher, research_company
from config import DefaultConfigs, validate_environment


async def example_basic_research():
    """Example 1: Basic company research"""
    print("\n🔍 Example 1: Basic Research")
    print("-" * 40)
    
    results = await research_company(
        company_name="Stripe",
        user_notes="Focus on payment processing and recent expansion"
    )
    
    # Print results
    researcher = CompanyResearcher()
    researcher.print_results(results)
    
    return results


async def example_custom_config():
    """Example 2: Research with custom configuration"""
    print("\n🔍 Example 2: Custom Configuration (Quick Research)")
    print("-" * 40)
    
    # Use quick research configuration
    config = DefaultConfigs.quick_research()
    
    researcher = CompanyResearcher(
        max_search_queries=config.max_search_queries,
        max_search_results=config.max_search_results,
        max_reflections=config.max_reflections
    )
    
    results = await researcher.research_company(
        company_name="Anthropic",
        user_notes="AI safety company, focus on Claude"
    )
    
    researcher.print_results(results)
    return results


async def example_thorough_research():
    """Example 3: Thorough research with more queries"""
    print("\n🔍 Example 3: Thorough Research")
    print("-" * 40)
    
    config = DefaultConfigs.thorough_research()
    
    researcher = CompanyResearcher(
        max_search_queries=config.max_search_queries,
        max_search_results=config.max_search_results,
        max_reflections=config.max_reflections
    )
    
    results = await researcher.research_company(
        company_name="Databricks",
        user_notes="Data and AI platform, recent IPO rumors"
    )
    
    researcher.print_results(results)
    return results


async def example_batch_research():
    """Example 4: Research multiple companies"""
    print("\n🔍 Example 4: Batch Research")
    print("-" * 40)
    
    companies = [
        {"name": "Notion", "notes": "Productivity and note-taking platform"},
        {"name": "Figma", "notes": "Design collaboration tool, acquired by Adobe"},
        {"name": "Linear", "notes": "Project management for software teams"}
    ]
    
    results = {}
    
    # Use quick config for batch processing
    config = DefaultConfigs.quick_research()
    researcher = CompanyResearcher(
        max_search_queries=config.max_search_queries,
        max_search_results=config.max_search_results,
        max_reflections=config.max_reflections
    )
    
    for company in companies:
        print(f"\n🔍 Researching {company['name']}...")
        
        result = await researcher.research_company(
            company_name=company['name'],
            user_notes=company['notes']
        )
        
        results[company['name']] = result
        
        # Brief summary
        info = result['company_info']
        print(f"✅ {company['name']}: {info.get('product_description', 'N/A')[:100]}...")
    
    return results


async def interactive_research():
    """Interactive research - ask user for company name"""
    print("\n🔍 Interactive Research")
    print("-" * 40)
    
    try:
        company_name = input("Enter company name to research: ").strip()
        if not company_name:
            print("❌ No company name provided")
            return None
        
        user_notes = input("Enter any specific notes (optional): ").strip()
        if not user_notes:
            user_notes = None
        
        print(f"\n🚀 Starting research for: {company_name}")
        
        results = await research_company(
            company_name=company_name,
            user_notes=user_notes
        )
        
        researcher = CompanyResearcher()
        researcher.print_results(results)
        
        # Ask if user wants to save results
        save = input("\nSave results to file? (y/n): ").strip().lower()
        if save == 'y':
            filename = f"{company_name.lower().replace(' ', '_')}_research.json"
            with open(filename, 'w') as f:
                json.dump(results, f, indent=2)
            print(f"💾 Results saved to: {filename}")
        
        return results
        
    except KeyboardInterrupt:
        print("\n❌ Research cancelled by user")
        return None


def save_results(results: Dict[str, Any], filename: str):
    """Save research results to JSON file"""
    with open(filename, 'w') as f:
        json.dump(results, f, indent=2)
    print(f"💾 Results saved to: {filename}")


async def main():
    """Main function to run examples"""
    
    print("🚀 Company Researcher Examples")
    print("=" * 50)
    
    # Validate environment
    env_check = validate_environment()
    if not env_check['valid']:
        print(f"❌ {env_check['message']}")
        print("Please set the required environment variables:")
        for var in env_check['missing_variables']:
            print(f"   - {var}")
        return
    
    print("✅ Environment validated")
    
    # Menu
    print("\nChoose an example to run:")
    print("1. Basic Research (Stripe)")
    print("2. Custom Config - Quick Research (Anthropic)")  
    print("3. Thorough Research (Databricks)")
    print("4. Batch Research (Multiple companies)")
    print("5. Interactive Research (Your choice)")
    print("6. Run all examples")
    
    try:
        choice = input("\nEnter choice (1-6): ").strip()
        
        if choice == "1":
            results = await example_basic_research()
            save_results(results, "stripe_research.json")
            
        elif choice == "2":
            results = await example_custom_config()
            save_results(results, "anthropic_research.json")
            
        elif choice == "3":
            results = await example_thorough_research()
            save_results(results, "databricks_research.json")
            
        elif choice == "4":
            results = await example_batch_research()
            save_results(results, "batch_research.json")
            
        elif choice == "5":
            results = await interactive_research()
            
        elif choice == "6":
            print("\n🚀 Running all examples...")
            
            results1 = await example_basic_research()
            save_results(results1, "stripe_research.json")
            
            results2 = await example_custom_config()
            save_results(results2, "anthropic_research.json")
            
            results3 = await example_batch_research()
            save_results(results3, "batch_research.json")
            
            print("\n✅ All examples completed!")
            
        else:
            print("❌ Invalid choice")
            
    except KeyboardInterrupt:
        print("\n❌ Cancelled by user")
    except Exception as e:
        print(f"❌ Error: {e}")


if __name__ == "__main__":
    asyncio.run(main())



File Name: models.py

-----------------------------

File Content: 

from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field


class CompanyInfo(BaseModel):
    """Basic information about a company"""
    company_name: str = Field(description="Official name of the company")
    founding_year: Optional[int] = Field(default=None, description="Year the company was founded")
    founder_names: List[str] = Field(default_factory=list, description="Names of the founding team members")
    product_description: Optional[str] = Field(default=None, description="Brief description of the company's main product or service")
    funding_summary: Optional[str] = Field(default=None, description="Summary of the company's funding history")
    notable_customers: Optional[str] = Field(default=None, description="Known customers that use company's product/service")


class SearchQuery(BaseModel):
    """Represents a search query to be executed"""
    query: str
    purpose: str  # What information this query is meant to find


class ResearchState(BaseModel):
    """State maintained throughout the research process"""
    company_name: str
    user_notes: Optional[str] = None
    messages: List[Dict[str, Any]] = Field(default_factory=list)
    search_queries_generated: List[SearchQuery] = Field(default_factory=list)
    search_results: List[Dict[str, Any]] = Field(default_factory=list)
    company_info: CompanyInfo = Field(default_factory=lambda: CompanyInfo(company_name=""))
    queries_executed: int = 0
    reflections_done: int = 0
    max_search_queries: int = 8
    max_search_results: int = 50
    max_reflections: int = 3
    research_complete: bool = False


class SearchResult(BaseModel):
    """Represents a search result from Tavily API"""
    title: str
    url: str
    content: str
    score: float
    raw_content: Optional[str] = None



File Name: nodes.py

-----------------------------

File Content: 

import asyncio
import json
from typing import List, Dict, Any
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from tavily import TavilyClient
import os
from models import ResearchState, SearchQuery, CompanyInfo, SearchResult


class QueryGenerationNode:
    """Node responsible for generating search queries"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
    
    async def __call__(self, state: ResearchState) -> ResearchState:
        """Generate search queries for company research"""
        
        # Don't generate more queries if we've reached the limit
        if state.queries_executed >= state.max_search_queries:
            return state
        
        # Determine how many queries to generate
        remaining_queries = state.max_search_queries - state.queries_executed
        queries_to_generate = min(4, remaining_queries)  # Generate up to 4 at a time
        
        # Build context from previous research
        context = ""
        if state.search_results:
            context = f"\nPrevious search results summary: {len(state.search_results)} results found"
        
        user_notes_context = f"\nUser notes: {state.user_notes}" if state.user_notes else ""
        
        system_prompt = f"""You are a research assistant. Generate {queries_to_generate} specific search queries to find information about the company "{state.company_name}".

Focus on finding:
1. Company founding year and founders
2. Product/service descriptions
3. Funding history and investors
4. Notable customers and partnerships
5. Recent news and developments

Current research progress:
- Company: {state.company_name}
- Queries executed: {state.queries_executed}/{state.max_search_queries}
- Current info: {state.company_info.model_dump()}
{context}{user_notes_context}

Generate diverse, specific queries that will help fill missing information. Return exactly {queries_to_generate} queries, each on a new line in this format:
QUERY: [search query]
PURPOSE: [what information this query aims to find]

Example:
QUERY: {state.company_name} founders founding team history
PURPOSE: Find founding year and founder names
"""

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"Generate {queries_to_generate} search queries for researching {state.company_name}")
        ]
        
        response = await self.llm.ainvoke(messages)
        
        # Parse the response to extract queries
        queries = []
        lines = response.content.strip().split('\n')
        
        current_query = None
        current_purpose = None
        
        for line in lines:
            line = line.strip()
            if line.startswith('QUERY:'):
                current_query = line[6:].strip()
            elif line.startswith('PURPOSE:'):
                current_purpose = line[8:].strip()
                if current_query and current_purpose:
                    queries.append(SearchQuery(query=current_query, purpose=current_purpose))
                    current_query = None
                    current_purpose = None
        
        # Add to state
        state.search_queries_generated.extend(queries)
        state.messages.append({
            "type": "query_generation",
            "queries": [q.model_dump() for q in queries],
            "total_generated": len(queries)
        })
        
        return state


class WebSearchNode:
    """Node responsible for executing web searches"""
    
    def __init__(self, tavily_client: TavilyClient):
        self.tavily_client = tavily_client
    
    async def __call__(self, state: ResearchState) -> ResearchState:
        """Execute web searches for pending queries"""
        
        # Get unexecuted queries
        unexecuted_queries = state.search_queries_generated[state.queries_executed:]
        
        if not unexecuted_queries:
            return state
        
        # Execute searches in parallel (but limit concurrency)
        search_tasks = []
        for query in unexecuted_queries:
            if state.queries_executed >= state.max_search_queries:
                break
            search_tasks.append(self._search_query(query.query))
            state.queries_executed += 1
        
        if search_tasks:
            # Execute searches with limited concurrency
            semaphore = asyncio.Semaphore(3)  # Max 3 concurrent searches
            
            async def limited_search(task):
                async with semaphore:
                    return await task
            
            search_results = await asyncio.gather(*[limited_search(task) for task in search_tasks])
            
            # Process and store results
            for i, results in enumerate(search_results):
                if results:
                    for result in results:
                        if len(state.search_results) < state.max_search_results:
                            state.search_results.append({
                                "query": unexecuted_queries[i].query,
                                "purpose": unexecuted_queries[i].purpose,
                                "title": result.get("title", ""),
                                "url": result.get("url", ""),
                                "content": result.get("content", ""),
                                "score": result.get("score", 0.0)
                            })
            
            state.messages.append({
                "type": "web_search",
                "queries_executed": len(search_tasks),
                "results_found": len([r for r in search_results if r]),
                "total_results": len(state.search_results)
            })
        
        return state
    
    async def _search_query(self, query: str) -> List[Dict[str, Any]]:
        """Execute a single search query"""
        try:
            # Use Tavily search
            response = self.tavily_client.search(
                query=query,
                search_depth="basic",
                include_images=False,
                include_answer=False,
                max_results=5
            )
            return response.get("results", [])
        except Exception as e:
            print(f"Search error for query '{query}': {e}")
            return []


class InformationExtractionNode:
    """Node responsible for extracting structured information from search results"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
    
    async def __call__(self, state: ResearchState) -> ResearchState:
        """Extract company information from search results"""
        
        if not state.search_results:
            return state
        
        # Prepare search results for processing
        search_context = ""
        for i, result in enumerate(state.search_results[-10:]):  # Use last 10 results
            search_context += f"\n--- Result {i+1} ---\n"
            search_context += f"Query: {result['query']}\n"
            search_context += f"Title: {result['title']}\n"
            search_context += f"Content: {result['content'][:500]}...\n"
        
        system_prompt = f"""You are an expert information extraction assistant. Extract and update company information from the provided search results.

Current company information:
{state.company_info.model_dump_json(indent=2)}

Based on the search results below, update the company information. Follow these rules:
1. Only update fields with confident, factual information
2. For founder_names, provide a list of individual names
3. Keep descriptions concise but informative
4. If you find conflicting information, use the most recent/reliable source
5. Leave fields as null/empty if no reliable information is found

Return the updated information in this exact JSON format:
{{
    "company_name": "string",
    "founding_year": integer or null,
    "founder_names": ["name1", "name2"] or [],
    "product_description": "string" or null,
    "funding_summary": "string" or null,
    "notable_customers": "string" or null
}}

Search Results:
{search_context}
"""

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"Extract and update information for {state.company_name}")
        ]
        
        response = await self.llm.ainvoke(messages)
        
        try:
            # Parse the JSON response
            import json
            # Find JSON in the response
            content = response.content.strip()
            if content.startswith('```json'):
                content = content[7:]
            if content.endswith('```'):
                content = content[:-3]
            
            extracted_data = json.loads(content)
            
            # Update the company info
            state.company_info = CompanyInfo(**extracted_data)
            
            state.messages.append({
                "type": "information_extraction",
                "extracted_fields": list(extracted_data.keys()),
                "updated_info": extracted_data
            })
            
        except Exception as e:
            print(f"Error parsing extracted information: {e}")
            state.messages.append({
                "type": "information_extraction_error",
                "error": str(e),
                "response": response.content
            })
        
        return state


class ReflectionNode:
    """Node responsible for determining if research is complete"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
    
    async def __call__(self, state: ResearchState) -> ResearchState:
        """Determine if we have sufficient information about the company"""
        
        # Check if we've exceeded reflection limit
        if state.reflections_done >= state.max_reflections:
            state.research_complete = True
            return state
        
        # Check if we've used all search queries
        if state.queries_executed >= state.max_search_queries:
            state.research_complete = True
            return state
        
        current_info = state.company_info.model_dump()
        
        system_prompt = f"""You are a research quality assessor. Evaluate if we have sufficient information about the company "{state.company_name}".

Current information gathered:
{json.dumps(current_info, indent=2)}

Research progress:
- Search queries executed: {state.queries_executed}/{state.max_search_queries}
- Search results collected: {len(state.search_results)}
- Reflections done: {state.reflections_done}/{state.max_reflections}

Evaluation criteria:
1. Do we have the company name? (Required)
2. Do we have founding year and/or founders?
3. Do we have a product/service description?
4. Do we have funding information?
5. Do we have notable customers?

Respond with either:
SUFFICIENT: [brief reason why research is complete]
OR
INSUFFICIENT: [specific gaps that need more research]

Focus on the most critical missing information that would make this research valuable.
"""

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content="Is the current company information sufficient?")
        ]
        
        response = await self.llm.ainvoke(messages)
        
        state.reflections_done += 1
        
        if response.content.strip().startswith('SUFFICIENT'):
            state.research_complete = True
            state.messages.append({
                "type": "reflection",
                "decision": "sufficient",
                "reason": response.content.strip()[11:].strip(),
                "reflection_number": state.reflections_done
            })
        else:
            state.research_complete = False
            state.messages.append({
                "type": "reflection", 
                "decision": "insufficient",
                "gaps": response.content.strip()[13:].strip(),
                "reflection_number": state.reflections_done
            })
        
        return state



File Name: test_basic.py

-----------------------------

File Content: 

#!/usr/bin/env python3
"""
Basic test script for the Company Researcher
"""

import asyncio
import sys
from company_researcher import research_company
from config import validate_environment


async def test_basic_research():
    """Test basic research functionality"""
    
    # Validate environment
    env_check = validate_environment()
    if not env_check['valid']:
        print(f"❌ Environment validation failed: {env_check['message']}")
        return False
    
    print("✅ Environment validation passed")
    
    try:
        print("🔍 Testing basic research with a quick search...")
        
        # Test with a well-known company
        results = await research_company(
            company_name="Google",
            user_notes="Quick test - focus on core information",
            max_search_queries=3,  # Limit for quick test
            max_reflections=1
        )
        
        # Check results
        company_info = results.get('company_info', {})
        research_summary = results.get('research_summary', {})
        
        print(f"✅ Research completed successfully!")
        print(f"   Company: {company_info.get('company_name', 'N/A')}")
        print(f"   Queries executed: {research_summary.get('queries_executed', 0)}")
        print(f"   Results collected: {research_summary.get('results_collected', 0)}")
        print(f"   Research complete: {research_summary.get('research_complete', False)}")
        
        # Basic validation
        if company_info.get('company_name'):
            print("✅ Company name extracted successfully")
        else:
            print("⚠️  No company name extracted")
        
        if research_summary.get('queries_executed', 0) > 0:
            print("✅ Search queries executed successfully")
        else:
            print("❌ No search queries executed")
        
        return True
        
    except Exception as e:
        print(f"❌ Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Main test function"""
    print("🧪 Company Researcher Basic Test")
    print("=" * 40)
    
    try:
        success = asyncio.run(test_basic_research())
        
        if success:
            print("\n✅ All tests passed! The company researcher is working correctly.")
            sys.exit(0)
        else:
            print("\n❌ Tests failed. Please check the configuration and API keys.")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n❌ Test cancelled by user")
        sys.exit(1)


if __name__ == "__main__":
    main()

